{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN_DTI Based Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader                                     \n",
    "from gnn import gnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import utils\n",
    "from train_tools import *\n",
    "import os, time, shutil\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opts: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_opts = Opts()\n",
    "gnn_opts.n_graph_layer = 4\n",
    "gnn_opts.d_graph_layer = 140\n",
    "gnn_opts.n_FC_layer = 4\n",
    "gnn_opts.d_FC_layer = 128\n",
    "gnn_opts.initial_mu = 4.46108546619827\n",
    "gnn_opts.initial_dev = 0.19818493842903845\n",
    "gnn_opts.dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_opts = Opts()\n",
    "learn_opts.num_epochs = 1000\n",
    "learn_opts.lr = 0.0001\n",
    "learn_opts.batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myopts = Opts()\n",
    "myopts.data_fpath = 'cbidata'\n",
    "myopts.save_dir = 'save'\n",
    "myopts.random_stratify = True\n",
    "myopts.cache_dir = '/tmp/moldata'\n",
    "# If you repeat experiments within the same dataset version, set to False\n",
    "myopts.clear_cache = False\n",
    "myopts.train_keys = 'keys/keys_refined'\n",
    "myopts.kinase_list = 'keys/kinase_list'\n",
    "# <- The newest is 3, still 1 and 2 are acceptible\n",
    "myopts.dataset_version = 3\n",
    "myopts.cpu_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert myopts.dataset_version in [1, 2, 3]\n",
    "_ver = myopts.dataset_version\n",
    "if _ver == 1:\n",
    "    import dataset as ds\n",
    "elif _ver == 2:\n",
    "    import dataset2 as ds\n",
    "else:\n",
    "    import dataset3 as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support functions for learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(model, loader, train=True):\n",
    "    losses = []\n",
    "    for sample in loader:\n",
    "        model.zero_grad()\n",
    "        H, A1, A2, Y, V, keys, _ = sample\n",
    "        H, A1, A2, Y, V = H.to(device), A1.to(device), A2.to(device), Y.to(device), V.to(device)\n",
    "\n",
    "        pred = model.train_model((H, A1, A2, V))\n",
    "\n",
    "        loss = loss_fn(pred, Y)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(loss.data.cpu().numpy())\n",
    "    mean_loss = np.mean(np.array(losses))\n",
    "    return mean_loss\n",
    "\n",
    "def test(model, loader):\n",
    "    test_true, test_pred, test_label = [], [], []\n",
    "\n",
    "    saliency_list = []\n",
    "    n_atom_list = []\n",
    "\n",
    "    model.eval()\n",
    "    for i_batch, sample in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "        H, A1, A2, Y, V, keys, n_atom = sample\n",
    "\n",
    "        embed = model.embede(H)\n",
    "        model.zero_grad()\n",
    "        pred = model.test_model((embed, A1, A2, V))\n",
    "\n",
    "        out = torch.sum(pred)\n",
    "        embed.retain_grad()\n",
    "        out.backward()\n",
    "        saliency = embed.grad.clone()\n",
    "        saliency *= embed.data.clone()\n",
    "\n",
    "        test_true.append(Y.data.cpu().numpy())\n",
    "        test_pred.append(pred.data.cpu().numpy())\n",
    "        test_label.append(keys)\n",
    "        saliency_list.append(saliency)\n",
    "        n_atom_list.append(n_atom)\n",
    "\n",
    "    test_pred = np.concatenate(np.array(test_pred), 0)\n",
    "    test_true = np.concatenate(np.array(test_true), 0)\n",
    "    return test_true, test_pred, test_label, saliency_list, n_atom_list\n",
    "\n",
    "def get_stats(X, y):\n",
    "    rmse = metrics.mean_squared_error(X, y)**0.5\n",
    "    mae = metrics.mean_absolute_error(X, y)\n",
    "    r2 = stats.pearsonr(X, y)\n",
    "    rho = stats.spearmanr(X, y)\n",
    "    return rmse, mae, r2[0], rho[0]\n",
    "\n",
    "def update_train_loss(train_loss, best_train_loss):\n",
    "    if train_loss < best_train_loss:\n",
    "        best_train_loss = train_loss\n",
    "    return best_train_loss\n",
    "\n",
    "def update_test_loss(model, opts, test_loss, best_val_loss, epoch):\n",
    "    output = False\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        output = True\n",
    "    if output:\n",
    "        torch.save(model.state_dict(), f'{opts.save_dir}/save_{epoch}.pt')\n",
    "        torch.save(model.state_dict(), f'{opts.save_dir}/model_weights.pt')\n",
    "    return best_val_loss, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if myopts.clear_cache:\n",
    "    try:\n",
    "        shutil.rmtree(myopts.cache_dir)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(myopts.save_dir, exist_ok=True)\n",
    "\n",
    "train = read_keyfile(myopts.train_keys)\n",
    "train_keys, test_keys, test2_keys = filter_and_stratify(train, random_stratify=myopts.random_stratify)\n",
    "\n",
    "\n",
    "test_keys.append(('0000', 8.77))\n",
    "write_keys(train_keys, 'train.local.key')\n",
    "write_keys(test_keys, 'test.local.key')\n",
    "write_keys(test2_keys, 'test2.local.key')\n",
    "\n",
    "len(train_keys), len(test_keys), len(test2_keys)\n",
    "for x in test_keys:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds.MolDataset([k for k, v in train_keys], [v for k, v in train_keys], myopts.data_fpath)\n",
    "test_dataset = ds.MolDataset([k for k, v in test_keys], [v for k, v in test_keys], myopts.data_fpath)\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gnn_opts.N_atom_features = train_dataset[0]['H'].shape[1]//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in test_dataset:\n",
    "    print(x['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, learn_opts.batch_size, shuffle=True, num_workers=myopts.cpu_count, collate_fn=ds.collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, learn_opts.batch_size, shuffle=True, num_workers=myopts.cpu_count, collate_fn=ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CLEAR_OUTPUT_WHEN_UPDATE = False\n",
    "SHOW_VERY_BAD_MOLS = True\n",
    "\n",
    "model = utils.initialize_model(gnn(gnn_opts), device)\n",
    "print ('number of parameters : ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learn_opts.lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "best_train_loss, best_val_loss = np.inf, np.inf\n",
    "\n",
    "Los = []\n",
    "Lps = []\n",
    "\n",
    "for epoch in range(learn_opts.num_epochs):\n",
    "    st = time.time()\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    model.train()\n",
    "    train_loss = learn(model, train_dataloader)\n",
    "    Los.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = learn(model, test_dataloader, train=False)\n",
    "    Lps.append(test_loss)\n",
    "\n",
    "    lapse = time.time() - st\n",
    "\n",
    "    best_train_loss = update_train_loss(train_loss, best_train_loss)\n",
    "    best_val_loss, output = update_test_loss(model, myopts, test_loss, best_val_loss, epoch)\n",
    "\n",
    "    ls = [f'Epoch: {epoch}',\n",
    "          f'Lapse: {lapse:.1f}s',\n",
    "          f'Losses: ({train_loss:.3f}, {test_loss:.3f})',\n",
    "          f'Best: ({best_train_loss:.3f}, {best_val_loss:.3f})']\n",
    "    print('\\t'.join(ls))\n",
    "\n",
    "    if output:\n",
    "        X, y, L, S, N = test(model, test_dataloader)\n",
    "        write_results_to_csv(L[0], X, y, np.abs(X-y), epoch)\n",
    "\n",
    "        rmse, mae, r2, rho = get_stats(X, y)\n",
    "        if CLEAR_OUTPUT_WHEN_UPDATE:\n",
    "            clear_output()\n",
    "        myplot(X, y, Los, Lps)\n",
    "        print(f'rmse: {rmse:5.3f}, mae: {mae:5.3f}, r2: {r2:5.3f}, rho: {rho:5.3f}')\n",
    "        if SHOW_VERY_BAD_MOLS:\n",
    "            show_bad_molecules(L, X, y, np.abs(X-y), len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
